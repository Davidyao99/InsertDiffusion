{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Replacement\n",
    "## Bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('\\\\')[-1] != 'InsertDiffusion' and os.getcwd().split('/')[-1] != 'InsertDiffusion':\n",
    "    os.chdir('..')\n",
    "\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORIZATION_MODEL = 'diffusers/stable-diffusion-xl-1.0-inpainting-0.1'\n",
    "UPSCALING_MODEL = 'stabilityai/stable-diffusion-x4-upscaler'\n",
    "COLORIZATION_NEGATIVE_PROMPT = \"black and white, black frame, silhouette, motorbike, toy, clay, model, missing saddle, high saddle, details, detailed, greyscale, duplicate, multiple, detached, shadow, contact shadow, drop shadow, reflection, ground, unrealistic, bad, distorted, ugly, weird\"\n",
    "COLORIZATION_FILL_HOLES = True\n",
    "COLORIZATION_DILATION = 8\n",
    "COLORIZATION_STRENGTH = 0.91\n",
    "COLORIZATION_GUIDANCE = 17\n",
    "COLORIZATION_MASK_THRESHOLD = 170\n",
    "COLORIZATION_STEPS = 30\n",
    "\n",
    "INPAINTING_MASK_THRESHOLD = 230\n",
    "INPAINTING_MODEL = 'stabilityai/stable-diffusion-2-inpainting'\n",
    "INPAINTING_NEGATIVE_PROMPT = \"wrong proportions, toy, black frame, motorbike, silhouette, model, clay, high saddle, large wheels, text, above floor, flying, changed bike color, white background, duplicate, multiple, people, basket, distortion, low quality, worst, ugly, fuzzy, blurry, cartoon, simple, art\"\n",
    "INPAINTING_GUIDANCE = 15\n",
    "INPAINTING_STEPS = 75\n",
    "\n",
    "IMG2IMG_MODEL = 'stabilityai/stable-diffusion-xl-refiner-1.0'\n",
    "IMG2IMG_STRENGTH = 0.2\n",
    "IMG2IMG_GUIDANCE = 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "bikes = [Image.open('./test_images/for_eval/bikes/sketch/' + x) for x in sorted(os.listdir('./test_images/for_eval/bikes/sketch/'))]\n",
    "\n",
    "with open('./test_images/for_eval/bikes/prompts.txt', 'r') as f:\n",
    "    prompts = f.readlines()\n",
    "bike_indices = [int(x.split('--')[0]) for x in prompts]\n",
    "colorization_prompts = [x.split('--')[1] for x in prompts]\n",
    "inpainting_prompts = [x.split('--')[2] for x in prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorization(image: Image, colorization_model: str, upscaling_model: str, colorization_prompt: str, colorization_negative_prompt: str, fill_holes: bool, dilation: int, strength: float, prompt_guidance: float):\n",
    "    colorized = utils.sd_colorization(colorization_model, upscaling_model, image, colorization_prompt, negative_prompt=colorization_negative_prompt, fill_holes=fill_holes, dilation_iterations=dilation, colorization_strength=strength, prompt_guidance=prompt_guidance)\n",
    "    return colorized\n",
    "\n",
    "def insert_diffusion(image: Image, mask_threshold: int, prompt: str, negative_prompt: str, img2img_model: str, inpainting_model: str, img2img_strength: float, inpainting_steps: int, inpainting_guidance: float, img2img_guidance: float) -> Image:\n",
    "    mask = utils.get_mask_from_image(image, mask_threshold)\n",
    "    inpainted = utils.sd_inpainting(inpainting_model, image, mask, prompt, negative_prompt, inpainting_guidance, inpainting_steps)\n",
    "    result = utils.sd_img2img(img2img_model, inpainted, prompt, negative_prompt, img2img_strength, img2img_guidance)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./test_images/eval_results/ours_ablation/bikes/', exist_ok=True)\n",
    "\n",
    "for i, bike in enumerate(bikes):\n",
    "    colorized = colorization(bike, COLORIZATION_MODEL, UPSCALING_MODEL, colorization_prompts[i], COLORIZATION_NEGATIVE_PROMPT, True, COLORIZATION_DILATION, COLORIZATION_STRENGTH, COLORIZATION_GUIDANCE)\n",
    "    inserted = insert_diffusion(colorized, INPAINTING_MASK_THRESHOLD, inpainting_prompts[i], INPAINTING_NEGATIVE_PROMPT, IMG2IMG_MODEL, INPAINTING_MODEL, IMG2IMG_STRENGTH, INPAINTING_STEPS, INPAINTING_GUIDANCE, IMG2IMG_GUIDANCE)\n",
    "    print(inpainting_prompts[i])\n",
    "    display(inserted)\n",
    "    inserted.save('./test_images/eval_results/ours_ablation/bikes/' + inpainting_prompts[i].split(',')[0] + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('\\\\')[-1] != 'InsertDiffusion' and os.getcwd().split('/')[-1] != 'InsertDiffusion':\n",
    "    os.chdir('..')\n",
    "\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "fp = './test_images/for_eval/products/ref/'\n",
    "product_filenames = os.listdir('./test_images/for_eval/products/ref/')\n",
    "\n",
    "prompts = [x.split('.')[0].split('_')[0] for x in product_filenames]\n",
    "product_descs = [x.split('.')[0].split('_')[1] for x in product_filenames]\n",
    "product_images = [Image.open(os.path.join(fp, x)) for x in product_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_THRESHOLD = 210\n",
    "INPAINTING_MODEL = 'stabilityai/stable-diffusion-2-inpainting'\n",
    "INPAINTING_NEGATIVE_PROMPT = \"wrong proportions, outline, white, collage, toy, silhouette, model, clay, above floor, flying, white background, duplicate, multiple, people, distortion, low quality, worst, ugly, fuzzy, blurry, cartoon, simple, art\"\n",
    "INPAINTING_GUIDANCE = 15\n",
    "INPAINTING_STEPS = 75\n",
    "\n",
    "IMG2IMG_MODEL = 'stabilityai/stable-diffusion-xl-refiner-1.0'\n",
    "IMG2IMG_STRENGTH = 0.15  # changed from 0.2!\n",
    "IMG2IMG_GUIDANCE = 7.5\n",
    "\n",
    "def inpaint_product_image(img: Image, prompt: str, object_name: str, mask_threshold: int=225):\n",
    "    try:\n",
    "        extracted = utils.get_pasted_image(img, object_name, erosion_strength=3)\n",
    "        repositioned = utils.paste_pipeline(extracted, 0.75, 0.5, 0.5, rescale=True)\n",
    "    except:\n",
    "        print('No erosion!')\n",
    "        extracted = utils.get_pasted_image(img, object_name, erosion_strength=0)\n",
    "        repositioned = utils.paste_pipeline(extracted, 0.75, 0.5, 0.5, rescale=True)\n",
    "    mask = utils.get_mask_from_image(repositioned, mask_threshold)\n",
    "\n",
    "    inpainted = utils.sd_inpainting(INPAINTING_MODEL, repositioned, mask, prompt, INPAINTING_NEGATIVE_PROMPT, INPAINTING_GUIDANCE, INPAINTING_STEPS)\n",
    "    final = utils.sd_img2img(IMG2IMG_MODEL, inpainted, prompt, INPAINTING_NEGATIVE_PROMPT, IMG2IMG_STRENGTH, IMG2IMG_GUIDANCE)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_images = []\n",
    "for i, img in enumerate(product_images):\n",
    "    final = inpaint_product_image(img, prompts[i], product_descs[i], MASK_THRESHOLD)\n",
    "    print(prompts[i])\n",
    "    display(final)\n",
    "    final_images.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = './test_images/eval_results/ours_ablation/products/'\n",
    "os.makedirs(out_fp, exist_ok=True)\n",
    "\n",
    "for i, img in enumerate(final_images):\n",
    "    fname = out_fp + prompts[i] + '.png'\n",
    "    img.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('\\\\')[-1] != 'InsertDiffusion' and os.getcwd().split('/')[-1] != 'InsertDiffusion':\n",
    "    os.chdir('..')\n",
    "\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "fp = './test_images/for_eval/cars/ref/'\n",
    "car_filenames = sorted(os.listdir(fp))\n",
    "\n",
    "prompts = [x.split('.')[0].split('_')[0] for x in car_filenames]\n",
    "car_images = [Image.open(os.path.join(fp, x)) for x in car_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_THRESHOLD = 130\n",
    "INPAINTING_MODEL = 'stabilityai/stable-diffusion-2-inpainting'\n",
    "INPAINTING_NEGATIVE_PROMPT = \"car, vehicle, cars, traffic, white background, floating, not on ground, flying, duplicate, multiple, people, antenna, distortion, low quality, worst, ugly, fuzzy, blurry, cartoon, simple, art\"\n",
    "INPAINTING_GUIDANCE = 15\n",
    "INPAINTING_STEPS = 75\n",
    "\n",
    "IMG2IMG_MODEL = 'stabilityai/stable-diffusion-xl-refiner-1.0'\n",
    "IMG2IMG_STRENGTH = 0.2\n",
    "IMG2IMG_GUIDANCE = 7.5\n",
    "\n",
    "def inpaint_car_image(img: Image, prompt: str, mask_threshold: int=180):\n",
    "    try:\n",
    "        extracted = utils.get_pasted_image(img, 'car', erosion_strength=3)\n",
    "        repositioned = utils.paste_pipeline(extracted, 0.75, 0.5, 0.5, rescale=True)\n",
    "    except:\n",
    "        print('No erosion!')\n",
    "        extracted = utils.get_pasted_image(img, 'car', erosion_strength=0)\n",
    "        repositioned = utils.paste_pipeline(extracted, 0.75, 0.5, 0.5, rescale=True)\n",
    "    mask = utils.get_mask_from_image(repositioned, mask_threshold)\n",
    "\n",
    "    inpainted = utils.sd_inpainting(INPAINTING_MODEL, repositioned, mask, prompt, INPAINTING_NEGATIVE_PROMPT, INPAINTING_GUIDANCE, INPAINTING_STEPS)\n",
    "    final = utils.sd_img2img(IMG2IMG_MODEL, inpainted, prompt, INPAINTING_NEGATIVE_PROMPT, IMG2IMG_STRENGTH, IMG2IMG_GUIDANCE)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_images = []\n",
    "for i, img in enumerate(car_images):\n",
    "    final = inpaint_car_image(img, prompts[i], MASK_THRESHOLD)\n",
    "    print(prompts[i])\n",
    "    display(final)\n",
    "    final_images.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_fp = './test_images/eval_results/ours_ablation/cars/'\n",
    "os.makedirs(out_fp, exist_ok=True)\n",
    "\n",
    "for i, img in enumerate(final_images):\n",
    "    img.save(out_fp + prompts[i] + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composition\n",
    "\n",
    "## Bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('\\\\')[-1] != 'InsertDiffusion' and os.getcwd().split('/')[-1] != 'InsertDiffusion':\n",
    "    os.chdir('..')\n",
    "\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "in_fp = './test_images/for_eval/bikes_composite'\n",
    "bike_data = pd.read_csv(os.path.join(in_fp, 'bike_data.csv'))\n",
    "\n",
    "bike_sketches = [Image.open(os.path.join(in_fp, 'sketches/' + x)) for x in sorted(os.listdir(os.path.join(in_fp, 'sketches')))]\n",
    "backgrounds = [Image.open(bike_data.loc[i, 'background']) for i, _ in enumerate(bike_sketches)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORIZATION_MODEL = 'diffusers/stable-diffusion-xl-1.0-inpainting-0.1'\n",
    "UPSCALING_MODEL = 'stabilityai/stable-diffusion-x4-upscaler'\n",
    "COLORIZATION_NEGATIVE_PROMPT = \"black and white, black frame, silhouette, motorbike, toy, clay, model, missing saddle, high saddle, details, detailed, greyscale, duplicate, multiple, detached, shadow, contact shadow, drop shadow, reflection, ground, unrealistic, bad, distorted, ugly, weird\"\n",
    "COLORIZATION_FILL_HOLES = True\n",
    "COLORIZATION_DILATION = 8\n",
    "COLORIZATION_STRENGTH = 0.91\n",
    "COLORIZATION_GUIDANCE = 17\n",
    "COLORIZATION_MASK_THRESHOLD = 170\n",
    "COLORIZATION_STEPS = 30\n",
    "\n",
    "INPAINTING_MASK_THRESHOLD = 200\n",
    "INPAINTING_MODEL = 'stabilityai/stable-diffusion-2-inpainting'\n",
    "INPAINTING_NEGATIVE_PROMPT = \"wrong proportions, toy, black frame, motorbike, silhouette, model, clay, high saddle, large wheels, text, above floor, flying, changed bike color, white background, duplicate, multiple, people, basket, distortion, low quality, worst, ugly, fuzzy, blurry, cartoon, simple, art\"\n",
    "INPAINTING_GUIDANCE = 15\n",
    "INPAINTING_STEPS = 75\n",
    "\n",
    "IMG2IMG_MODEL = 'stabilityai/stable-diffusion-xl-refiner-1.0'\n",
    "IMG2IMG_STRENGTH = 0.2\n",
    "IMG2IMG_GUIDANCE = 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paste_image(fg, bg):\n",
    "    fg = fg.copy()\n",
    "    bg = bg.copy()\n",
    "\n",
    "    fg = fg.convert('RGBA')\n",
    "    \n",
    "    # replace white with tranparent\n",
    "    pixdata = fg.load()\n",
    "    bg_color = pixdata[0, 0]\n",
    "    fuzziness = 20\n",
    "    for y in range(fg.size[0]):\n",
    "        for x in range(fg.size[1]):\n",
    "            should_replace = True\n",
    "            for idx in range(3):\n",
    "                if abs(pixdata[x, y][idx] - bg_color[idx]) > fuzziness:\n",
    "                    should_replace = False\n",
    "            if should_replace:\n",
    "                pixdata[x, y] = (0, 0, 0, 0)\n",
    "    \n",
    "    bg.paste(fg, (0, 0), fg)\n",
    "    return bg\n",
    "\n",
    "def do_insert_diffusion(fg: Image, bg: Image, positioning: dict, prompt: str, strength: float, img2img_strength: float):\n",
    "    fg = utils.paste_pipeline(fg, positioning['scale'], positioning['fraction_down'], positioning['fraction_right'], False, rotation=positioning['rotation'])\n",
    "    mask = utils.get_mask_from_image(fg, INPAINTING_MASK_THRESHOLD)\n",
    "\n",
    "    if fg.width < bg.width:\n",
    "        fraction = bg.width/img.width\n",
    "        fg = fg.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "        mask = mask.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "    if fg.height < bg.height:\n",
    "        fraction = bg.height/img.height\n",
    "        fg = fg.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "        mask = mask.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "\n",
    "    pasted_img = paste_image(fg, bg)\n",
    "    inpainted = utils.sd_inpainting(INPAINTING_MODEL, pasted_img, mask, prompt, INPAINTING_NEGATIVE_PROMPT, INPAINTING_GUIDANCE, INPAINTING_STEPS, inpainting_strength=strength)\n",
    "    final = utils.sd_img2img(IMG2IMG_MODEL, inpainted, prompt, INPAINTING_NEGATIVE_PROMPT, img2img_strength, IMG2IMG_GUIDANCE)\n",
    "    return final\n",
    "\n",
    "def colorization(image: Image, colorization_model: str, upscaling_model: str, colorization_prompt: str, colorization_negative_prompt: str, fill_holes: bool, dilation: int, strength: float, prompt_guidance: float):\n",
    "    colorized = utils.sd_colorization(colorization_model, upscaling_model, image, colorization_prompt, negative_prompt=colorization_negative_prompt, fill_holes=fill_holes, dilation_iterations=dilation, colorization_strength=strength, prompt_guidance=prompt_guidance)\n",
    "    return colorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRENGTH = 0.38\n",
    "IMG2IMG_STRENGTH = 0.2\n",
    "\n",
    "result_imgs = []\n",
    "for i, bike in enumerate(bike_sketches):\n",
    "    colorized = colorization(bike, COLORIZATION_MODEL, UPSCALING_MODEL, bike_data.loc[i, 'col_prompt'], COLORIZATION_NEGATIVE_PROMPT, COLORIZATION_FILL_HOLES, COLORIZATION_DILATION, COLORIZATION_STRENGTH, COLORIZATION_GUIDANCE)\n",
    "    curr = do_insert_diffusion(colorized, backgrounds[i], bike_data.iloc[i].to_dict(), bike_data.loc[i, 'inpainting_prompts'], STRENGTH, IMG2IMG_STRENGTH)\n",
    "    print('Prompt: ', bike_data.loc[i, 'inpainting_prompts'])\n",
    "    display(curr)\n",
    "    result_imgs.append(curr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = './test_images/eval_results/ours_composite_ablation/bikes'\n",
    "os.makedirs(fp, exist_ok=True)\n",
    "\n",
    "for i, ri in enumerate(result_imgs):\n",
    "    ri.save(os.path.join(fp, bike_data.loc[i, 'inpainting_prompts'] + '.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('\\\\')[-1] != 'InsertDiffusion' and os.getcwd().split('/')[-1] != 'InsertDiffusion':\n",
    "    os.chdir('..')\n",
    "\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "in_fp = './test_images/for_eval/cars_composite'\n",
    "car_data = pd.read_csv(os.path.join(in_fp, 'car_data.csv'))\n",
    "\n",
    "ref_files = os.listdir(os.path.join(in_fp, 'ref'))\n",
    "ref_files.sort(key=lambda x: int(x.split('.')[0]))\n",
    "bg_files = os.listdir(os.path.join(in_fp, 'backgrounds'))\n",
    "bg_files.sort(key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "car_images = [Image.open(os.path.join(in_fp, 'ref/' + x)) for x in ref_files]\n",
    "backgrounds = [Image.open(os.path.join(in_fp, 'backgrounds/' + x)) for x in bg_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORIZATION_MODEL = 'diffusers/stable-diffusion-xl-1.0-inpainting-0.1'\n",
    "UPSCALING_MODEL = 'stabilityai/stable-diffusion-x4-upscaler'\n",
    "COLORIZATION_NEGATIVE_PROMPT = \"black and white, black frame, silhouette, motorbike, toy, clay, model, missing saddle, high saddle, details, detailed, greyscale, duplicate, multiple, detached, shadow, contact shadow, drop shadow, reflection, ground, unrealistic, bad, distorted, ugly, weird\"\n",
    "COLORIZATION_FILL_HOLES = True\n",
    "COLORIZATION_DILATION = 8\n",
    "COLORIZATION_STRENGTH = 0.91\n",
    "COLORIZATION_GUIDANCE = 17\n",
    "COLORIZATION_MASK_THRESHOLD = 170\n",
    "COLORIZATION_STEPS = 30\n",
    "\n",
    "INPAINTING_MASK_THRESHOLD = 200\n",
    "INPAINTING_MODEL = 'stabilityai/stable-diffusion-2-inpainting'\n",
    "INPAINTING_NEGATIVE_PROMPT = \"wrong proportions, toy, black frame, motorbike, silhouette, model, clay, high saddle, large wheels, text, above floor, flying, changed bike color, white background, duplicate, multiple, people, basket, distortion, low quality, worst, ugly, fuzzy, blurry, cartoon, simple, art\"\n",
    "INPAINTING_GUIDANCE = 15\n",
    "INPAINTING_STEPS = 75\n",
    "\n",
    "IMG2IMG_MODEL = 'stabilityai/stable-diffusion-xl-refiner-1.0'\n",
    "IMG2IMG_STRENGTH = 0.2\n",
    "IMG2IMG_GUIDANCE = 7.5\n",
    "\n",
    "def inpaint_car_image(fg: Image, bg: Image, prompt: str, positioning: dict, mask_threshold: int=180):\n",
    "    fg = utils.extract_object(fg, bg, 'car')\n",
    "    fg = utils.paste_pipeline(fg, positioning['scale'], positioning['fraction_down'], positioning['fraction_right'], rescale=False, rotation=positioning['rotation'])\n",
    "    mask = utils.get_mask_from_image(fg, mask_threshold)\n",
    "\n",
    "    if fg.width < bg.width:\n",
    "        fraction = bg.width/img.width\n",
    "        fg = fg.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "        mask = mask.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "    if fg.height < bg.height:\n",
    "        fraction = bg.height/img.height\n",
    "        fg = fg.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "        mask = mask.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "    \n",
    "    pasted_img = utils.paste_image(fg, bg)\n",
    "\n",
    "    inpainted = utils.sd_inpainting(INPAINTING_MODEL, pasted_img, mask, prompt, INPAINTING_NEGATIVE_PROMPT, INPAINTING_GUIDANCE, INPAINTING_STEPS, inpainting_strength=STRENGTH)\n",
    "    final = utils.sd_img2img(IMG2IMG_MODEL, inpainted, prompt, INPAINTING_NEGATIVE_PROMPT, IMG2IMG_STRENGTH, IMG2IMG_GUIDANCE)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRENGTH = 0.38\n",
    "IMG2IMG_STRENGTH = 0.2\n",
    "\n",
    "final_images = []\n",
    "for i, img in enumerate(car_images):\n",
    "    final = inpaint_car_image(img, backgrounds[i], car_data.loc[i, 'prompt'], car_data.iloc[i].to_dict(), 230)\n",
    "    print(car_data.loc[i, 'prompt'])\n",
    "    display(final)\n",
    "    final_images.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = './test_images/eval_results/ours_composite_ablation/cars'\n",
    "os.makedirs(fp, exist_ok=True)\n",
    "\n",
    "for i, fi in enumerate(final_images):\n",
    "    fi.save(os.path.join(fp, car_data.loc[i, 'prompt'] + '.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('\\\\')[-1] != 'InsertDiffusion' and os.getcwd().split('/')[-1] != 'InsertDiffusion':\n",
    "    os.chdir('..')\n",
    "\n",
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "in_fp = './test_images/for_eval/products_composite'\n",
    "product_data = pd.read_csv(os.path.join(in_fp, 'product_data.csv'))\n",
    "\n",
    "ref_files = os.listdir(os.path.join(in_fp, 'ref'))\n",
    "ref_files.sort(key=lambda x: int(x.split('.')[0]))\n",
    "bg_files = os.listdir(os.path.join(in_fp, 'backgrounds'))\n",
    "bg_files.sort(key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "product_images = [Image.open(os.path.join(in_fp, 'ref/' + x)) for x in ref_files]\n",
    "backgrounds = [Image.open(os.path.join(in_fp, 'backgrounds/' + x)) for x in bg_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_THRESHOLD = 200\n",
    "INPAINTING_MODEL = 'stabilityai/stable-diffusion-2-inpainting'\n",
    "INPAINTING_NEGATIVE_PROMPT = \"wrong proportions, outline, white, collage, toy, silhouette, model, clay, above floor, flying, white background, duplicate, multiple, people, distortion, low quality, worst, ugly, fuzzy, blurry, cartoon, simple, art\"\n",
    "INPAINTING_GUIDANCE = 15\n",
    "INPAINTING_STEPS = 75\n",
    "\n",
    "IMG2IMG_MODEL = 'stabilityai/stable-diffusion-xl-refiner-1.0'\n",
    "IMG2IMG_STRENGTH = 0.15  # changed from 0.2!\n",
    "IMG2IMG_GUIDANCE = 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inpaint_product_image(fg: Image, bg: Image, prompt: str, object_desc: str, positioning: dict, mask_threshold: int=180):\n",
    "    fg = utils.extract_object(fg, bg, object_desc)\n",
    "    fg = utils.paste_pipeline(fg, positioning['scale'], positioning['fraction_down'], positioning['fraction_right'], rescale=False, rotation=positioning['rotation'])\n",
    "    mask = utils.get_mask_from_image(fg, mask_threshold)\n",
    "\n",
    "    if fg.width < bg.width:\n",
    "        fraction = bg.width/img.width\n",
    "        fg = fg.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "        mask = mask.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "    if fg.height < bg.height:\n",
    "        fraction = bg.height/img.height\n",
    "        fg = fg.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "        mask = mask.resize((int(fraction * fg.width), int(fraction * fg.height)), Image.Resampling.NEAREST)\n",
    "    \n",
    "    pasted_img = utils.paste_image(fg, bg)\n",
    "\n",
    "    inpainted = utils.sd_inpainting(INPAINTING_MODEL, pasted_img, mask, prompt, INPAINTING_NEGATIVE_PROMPT, INPAINTING_GUIDANCE, INPAINTING_STEPS, inpainting_strength=STRENGTH)\n",
    "    final = utils.sd_img2img(IMG2IMG_MODEL, inpainted, prompt, INPAINTING_NEGATIVE_PROMPT, IMG2IMG_STRENGTH, IMG2IMG_GUIDANCE)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRENGTH = 0.38\n",
    "IMG2IMG_STRENGTH = 0.18\n",
    "\n",
    "final_images = []\n",
    "\n",
    "for i, product in enumerate(product_images):\n",
    "    final = inpaint_product_image(product, backgrounds[i], product_data.loc[i, 'prompt'], product_data.loc[i, 'object_desc'], product_data.iloc[i].to_dict(), MASK_THRESHOLD)\n",
    "    print(product_data.loc[i, 'prompt'])\n",
    "    display(final)\n",
    "    final_images.append(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = './test_images/eval_results/ours_composite_ablation/products'\n",
    "os.makedirs(fp, exist_ok=True)\n",
    "\n",
    "for i, fi in enumerate(final_images):\n",
    "    fi.save(os.path.join(fp, product_data.loc[i, 'prompt'] + '.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
